{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# \ud83e\uddd1\u200d\ud83c\udf93 Student Version \u2014 Solutions Removed\n- Use the reflection prompts and hints.\n- Your instructor will share solutions separately."}, {"cell_type": "code", "metadata": {}, "source": "REVEAL_SOLUTIONS = False\nprint('Solutions are hidden in the Student Version.')", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "# Pandas in Google Colab \u2014 2-Hour Hands-On (+ Advanced & Capstone)\n**With Reflection Prompts After Each Section**\n**Last updated:** 2025-08-15\n\nRun top-to-bottom. Attempt **Exercises**, then write your **\u270d\ufe0f Analysis** under each section."}, {"cell_type": "markdown", "metadata": {}, "source": "## 0) Setup & Load the **tips** dataset (10m)"}, {"cell_type": "code", "metadata": {}, "source": "import pandas as pd, numpy as np, matplotlib.pyplot as plt\npd.set_option('display.max_rows', 10); pd.set_option('display.precision', 3)\nurl = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\"\ntips = pd.read_csv(url); tips.head()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "print(\"Shape:\", tips.shape)\nprint(\"\\nInfo:\"); print(tips.info())\nprint(\"\\nDescribe:\"); display(tips.describe(include='all'))", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "**Columns**: `total_bill` (float), `tip` (float), `sex` (str), `smoker` (str), `day` (str), `time` (str), `size` (int)"}, {"cell_type": "markdown", "metadata": {}, "source": "### \u2705 Exercise 0\n1) Unique `day`, `time`. 2) Count duplicates. 3) Averages of `total_bill`, `tip`."}, {"cell_type": "markdown", "metadata": {}, "source": "**Hints:**\n- Concept: inspect levels and duplicates.\n- API: `unique`, `duplicated`, `mean`.\n"}, {"cell_type": "code", "metadata": {}, "source": "# YOUR WORK: Exercise 0", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u270d\ufe0f Analysis (Setup & Load) \u2014 3\u20135 sentences\n- What columns and dtypes did you observe? Any surprises?\n- Is the dataset balanced across `day` and `time`? Cite one count.\n- One risk if you skip an initial audit here.\n\n### \ud83d\udd0e Quick checks\n- Report the shape (rows, cols).\n- Name 1 non-numeric dtype and why it matters.\n\n### \u2795 Extension (pick one)\n- Tweak display options and note the effect.\n- Compute `value_counts()` on `day` or `time`.\n\n**Rubric (10 pts):** Correctness 3 \u2022 Evidence 2 \u2022 Clarity 2 \u2022 Reproducibility 2 \u2022 Exploration 1"}, {"cell_type": "markdown", "metadata": {}, "source": "## 1) Import & Core Manipulation (20m)"}, {"cell_type": "code", "metadata": {}, "source": "tips[['total_bill','tip']].head()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "tips.iloc[0:5]", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "tips.loc[tips['day']=='Sun', ['total_bill','tip','size']].head()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "tips.query(\"time=='Lunch' and smoker=='Yes'\").head()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "tips.sort_values(['total_bill','tip'], ascending=[False, True]).head()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "tips = tips.assign(tip_pct = tips['tip']/tips['total_bill'],\n                         tip_per_person = tips['tip']/tips['size']); tips.head()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u2705 Exercise 1\nFilter `day='Sat' & size\u22653`, add `bill_per_person`, sort desc, show top 5."}, {"cell_type": "markdown", "metadata": {}, "source": "**Hints:**\n- Concept: filter \u2192 compute \u2192 sort.\n- API: boolean mask / `.query`, `.assign`, `.sort_values`.\n"}, {"cell_type": "code", "metadata": {}, "source": "# YOUR WORK: Exercise 1", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u270d\ufe0f Analysis (Import & Manipulation) \u2014 3\u20135 sentences\n- Which 2 columns seem most associated with `tip`? Support with a stat.\n- Explain one filter you wrote in plain English.\n- One thing you might compute next.\n\n### \ud83d\udd0e Quick checks\n- Show first 3 rows of your filtered frame.\n- Name one new column and its formula.\n\n### \u2795 Extension (pick one)\n- Rewrite a filter via `.query` vs mask; compare readability.\n- Change a sort order and predict effect.\n\n**Rubric (10 pts):** Correctness 3 \u2022 Evidence 2 \u2022 Clarity 2 \u2022 Reproducibility 2 \u2022 Exploration 1"}, {"cell_type": "markdown", "metadata": {}, "source": "## 2) Cleaning & Preprocessing (15m)"}, {"cell_type": "code", "metadata": {}, "source": "tips['sex']=tips['sex'].astype('category')\ntips['smoker']=tips['smoker'].astype('category')\ntips['day']=tips['day'].astype('category')\ntips['time']=tips['time'].astype('category'); tips.dtypes", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "tips['server_name'] = [' Alice ', 'Bob', 'ALICE', 'bob', ' Alice ', 'Bob'] * (len(tips)//6) + ['Alice']*(len(tips)%6)\ntips['server_name'] = tips['server_name'].str.strip().str.title()\ntips['server_name'].head()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "demo = tips.copy()\ndemo = pd.concat([demo, demo.iloc[0:2]], ignore_index=True)\nprint(\"Before:\", demo.shape, \"After:\", demo.drop_duplicates().shape)", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u2705 Exercise 2\n1) Ensure `size` is int64. 2) Build `tips_clean` with selected cols. 3) Verify no duplicates."}, {"cell_type": "markdown", "metadata": {}, "source": "**Hints:**\n- Concept: enforce types, subset columns, dedup.\n- API: `.astype`, column lists, `.drop_duplicates`.\n"}, {"cell_type": "code", "metadata": {}, "source": "# YOUR WORK: Exercise 2", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u270d\ufe0f Analysis (Cleaning & Preprocessing) \u2014 3\u20135 sentences\n- Which dtype changes did you apply and why?\n- Did you handle duplicates? How many?\n- One naming or string normalization you made.\n\n### \ud83d\udd0e Quick checks\n- Print memory usage pre/post for 1 cast.\n- Confirm duplicates=0 in `tips_clean`.\n\n### \u2795 Extension (pick one)\n- Cast another column and report memory delta.\n- Show `.value_counts()` pre/post string cleanup.\n\n**Rubric (10 pts):** Correctness 3 \u2022 Evidence 2 \u2022 Clarity 2 \u2022 Reproducibility 2 \u2022 Exploration 1"}, {"cell_type": "markdown", "metadata": {}, "source": "## 3) Handling Missing Data (15m)"}, {"cell_type": "code", "metadata": {}, "source": "rng = np.random.default_rng(42)\ntips_na = tips_clean.copy()\nmask = rng.choice([True, False], size=len(tips_na), p=[0.1, 0.9])\ntips_na.loc[mask, 'tip'] = np.nan; tips_na.loc[mask, 'size'] = np.nan\ntips_na.isna().sum()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "dropped = tips_na.dropna(); dropped.shape", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "filled = tips_na.fillna({'tip': tips_na['tip'].median(), 'size': tips_na['size'].median()}); filled.isna().sum()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "tips_group_fill = tips_na.copy()\ntips_group_fill['tip'] = tips_group_fill.groupby(['day','time'])['tip'].transform(lambda s: s.fillna(s.median()))\ntips_group_fill.isna().sum()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "tips_interp = tips_na.sort_values('total_bill').interpolate(numeric_only=True); tips_interp.isna().sum()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u2705 Exercise 3\nDrop rows where both `tip` & `size` are NaN; fill `size` by rounded mean per `day`."}, {"cell_type": "markdown", "metadata": {}, "source": "**Hints:**\n- Concept: selective drop, grouped fill.\n- API: boolean masks, `groupby().transform`, `.fillna`.\n"}, {"cell_type": "code", "metadata": {}, "source": "# YOUR WORK: Exercise 3", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u270d\ufe0f Analysis (Missing Data) \u2014 3\u20135 sentences\n- Compare `dropna` vs groupwise fill\u2014who shifts distribution more?\n- What assumption does your fill strategy make?\n- When would interpolation be inappropriate here?\n\n### \ud83d\udd0e Quick checks\n- Report NaN counts before vs after.\n- Cite one numeric change for `tip`.\n\n### \u2795 Extension (pick one)\n- Try a different group key for fill and compare MAE.\n- Plot hist pre/post fill for `tip`.\n\n**Rubric (10 pts):** Correctness 3 \u2022 Evidence 2 \u2022 Clarity 2 \u2022 Reproducibility 2 \u2022 Exploration 1"}, {"cell_type": "markdown", "metadata": {}, "source": "## 4) Analysis & Visualization (20m)"}, {"cell_type": "code", "metadata": {}, "source": "print(\"Overall tip %:\", (tips['tip'].sum()/tips['total_bill'].sum()).round(3))", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "plt.figure(); plt.hist(tips['total_bill'].dropna(), bins=20)\nplt.title('Histogram: total_bill'); plt.xlabel('total_bill'); plt.ylabel('Frequency'); plt.show()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "plt.figure()\ndata = [tips.loc[tips['day']==d, 'tip'].dropna().values for d in tips['day'].cat.categories]\nplt.boxplot(data, labels=list(tips['day'].cat.categories))\nplt.title('Boxplot: tip by day'); plt.xlabel('day'); plt.ylabel('tip'); plt.show()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "plt.figure(); plt.scatter(tips['total_bill'], tips['tip'], s=tips['size']*10, alpha=0.6)\nplt.title('Scatter: total_bill vs tip'); plt.xlabel('total_bill'); plt.ylabel('tip'); plt.show()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "avg_tip_pct = tips.groupby('day')['tip_pct'].mean()\nplt.figure(); plt.bar(avg_tip_pct.index.astype(str), avg_tip_pct.values)\nplt.title('Average tip_pct by day'); plt.xlabel('day'); plt.ylabel('mean tip_pct'); plt.show()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u2705 Exercise 4\n1) Scatter: `total_bill` vs `tip_pct`. 2) Bar: median `total_bill` by `time`."}, {"cell_type": "markdown", "metadata": {}, "source": "**Hints:**\n- Concept: relate vars via scatter; summarize via bar.\n- API: `plt.scatter`, `groupby().median` + `plt.bar`.\n"}, {"cell_type": "code", "metadata": {}, "source": "# YOUR WORK: Exercise 4", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u270d\ufe0f Analysis (Analysis & Visualization) \u2014 3\u20135 sentences\n- State one pattern that holds across days and one that differs Lunch vs Dinner.\n- Interpret scatter: linear? heteroscedastic?\n- What would you plot next?\n\n### \ud83d\udd0e Quick checks\n- Quote one `.describe()` stat that supports your claim.\n- Ensure axes labels/titles are informative.\n\n### \u2795 Extension (pick one)\n- Add a follow-up chart (e.g., tip% by party size) and describe it.\n- Bucket `total_bill` and compare medians.\n\n**Rubric (10 pts):** Correctness 3 \u2022 Evidence 2 \u2022 Clarity 2 \u2022 Reproducibility 2 \u2022 Exploration 1"}, {"cell_type": "markdown", "metadata": {}, "source": "## 5) Grouping & Merging (20m)"}, {"cell_type": "code", "metadata": {}, "source": "g = (tips.groupby(['day','time'])\n       .agg(count=('total_bill','size'), avg_bill=('total_bill','mean'),\n            avg_tip=('tip','mean'), avg_tip_pct=('tip_pct','mean'))); g.head()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "def pct_above_20(s): return (s>0.20).mean()\n\ntips.groupby('day')['tip_pct'].apply(pct_above_20)", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "day_lookup = pd.DataFrame({'day':['Thur','Fri','Sat','Sun'],'is_weekend':[False,False,True,True]})\ntips_merge = tips.merge(day_lookup, on='day', how='left')\ntips_merge[['day','is_weekend']].drop_duplicates().sort_values('day')", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u2705 Exercise 5\n1) Sum `total_bill` & `tip` by `smoker,sex`. 2) Map `time`\u2192L/D and show pairs."}, {"cell_type": "markdown", "metadata": {}, "source": "**Hints:**\n- Concept: summarize by groups; enrich via merge.\n- API: `groupby().agg`, `.merge`.\n"}, {"cell_type": "code", "metadata": {}, "source": "# YOUR WORK: Exercise 5", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u270d\ufe0f Analysis (Grouping & Merging) \u2014 3\u20135 sentences\n- Translate one grouped table into a business insight.\n- How does `tip_pct` vs `tip` change ranking?\n- What join-key assumptions are you making?\n\n### \ud83d\udd0e Quick checks\n- Show index/columns of grouped result.\n- Check row counts before/after a merge.\n\n### \u2795 Extension (pick one)\n- Add `avg_tip_pp` and re-rank groups.\n- Outer join with `_indicator` and explain one mismatch.\n\n**Rubric (10 pts):** Correctness 3 \u2022 Evidence 2 \u2022 Clarity 2 \u2022 Reproducibility 2 \u2022 Exploration 1"}, {"cell_type": "markdown", "metadata": {}, "source": "## 6) Reshaping & Pivoting (15m)"}, {"cell_type": "code", "metadata": {}, "source": "piv = tips.pivot_table(index='day', columns='time', values='tip_pct', aggfunc='mean'); piv", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "long = tips[['day','time','total_bill','tip']].melt(id_vars=['day','time'], var_name='metric', value_name='value'); long.head()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u2705 Exercise 6\n1) Pivot mean `total_bill` by `size`\u00d7`day`. 2) Melt back to long with `size` as id."}, {"cell_type": "markdown", "metadata": {}, "source": "**Hints:**\n- Concept: reshape wide\u2194long.\n- API: `pivot_table`, `melt`.\n"}, {"cell_type": "code", "metadata": {}, "source": "# YOUR WORK: Exercise 6", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u270d\ufe0f Analysis (Reshaping & Pivoting) \u2014 3\u20135 sentences\n- When did `pivot_table` drop rows/cols vs `melt`?\n- Explain wide\u2194long trade-offs here.\n- Which format suits your chosen chart and why?\n\n### \ud83d\udd0e Quick checks\n- Confirm shapes of pivot vs long tables.\n- List index/columns used in your pivot.\n\n### \u2795 Extension (pick one)\n- Change `aggfunc` and compare results.\n- Add a second dimension in pivot.\n\n**Rubric (10 pts):** Correctness 3 \u2022 Evidence 2 \u2022 Clarity 2 \u2022 Reproducibility 2 \u2022 Exploration 1"}, {"cell_type": "markdown", "metadata": {}, "source": "## 7) Mini-Project: When are tips the most generous? (5\u201310m)"}, {"cell_type": "code", "metadata": {}, "source": "piv = tips.pivot_table(index='day', columns='time', values='tip_pct', aggfunc='mean')\nprint(piv.stack().sort_values(ascending=False).head(5))\nplt.figure(); plt.imshow(piv.values, aspect='auto')\nplt.title('Mean tip_pct by day & time'); plt.xlabel('time'); plt.ylabel('day')\nplt.xticks(range(len(piv.columns)), piv.columns.astype(str))\nplt.yticks(range(len(piv.index)), piv.index.astype(str))\nplt.colorbar(); plt.show()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u270d\ufe0f Analysis (Mini-Project (Tips Generosity)) \u2014 3\u20135 sentences\n- State your top day\u00d7time combo with mean `tip_pct`.\n- Is it robust to outliers? How to check?\n- One follow-up action for a restaurant.\n\n### \ud83d\udd0e Quick checks\n- Show top 3 combos and their counts.\n- Confirm sample size for top combo.\n\n### \u2795 Extension (pick one)\n- Recompute using median `tip_pct`.\n- Exclude size<2 and compare ranking.\n\n**Rubric (10 pts):** Correctness 3 \u2022 Evidence 2 \u2022 Clarity 2 \u2022 Reproducibility 2 \u2022 Exploration 1"}, {"cell_type": "markdown", "metadata": {}, "source": "# Advanced Module \u2014 Daily Operations Coverage (~60\u201375m)"}, {"cell_type": "markdown", "metadata": {}, "source": "## 8) Indexes & MultiIndex (10m)"}, {"cell_type": "code", "metadata": {}, "source": "ti = tips.set_index(['day','time']).sort_index()\nti.loc[('Sat','Dinner')].head()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "ti.groupby(level=['day','time'])['tip_pct'].mean().reset_index(name='mean_tip_pct').head()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u270d\ufe0f Analysis (Indexes & MultiIndex) \u2014 3\u20135 sentences\n- What did a MultiIndex buy you over flat columns?\n- Give one easier slice enabled by the index.\n- Any pitfalls when saving/loading with MultiIndex?\n\n### \ud83d\udd0e Quick checks\n- Print `.index.names` and level dtypes.\n- Show one `.loc` label slice on multi-level.\n\n### \u2795 Extension (pick one)\n- Swap levels and explain slicing change.\n- Reset index and compare to original columns.\n\n**Rubric (10 pts):** Correctness 3 \u2022 Evidence 2 \u2022 Clarity 2 \u2022 Reproducibility 2 \u2022 Exploration 1"}, {"cell_type": "markdown", "metadata": {}, "source": "## 9) Time Series & Resampling (15m)"}, {"cell_type": "code", "metadata": {}, "source": "tips_ts = tips.copy()\ntips_ts['date'] = pd.to_datetime('2024-01-01') + pd.to_timedelta(np.arange(len(tips_ts)), unit='D')\ntips_ts = tips_ts.set_index('date').sort_index()\nweekly = tips_ts.resample('W')[['total_bill','tip']].sum()\nweekly['tip_pct'] = weekly['tip']/weekly['total_bill']\nweekly['tip_pct_roll4'] = weekly['tip_pct'].rolling(4, min_periods=1).mean()\nweekly.head()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u270d\ufe0f Analysis (Time Series & Resampling) \u2014 3\u20135 sentences\n- What trend do you see weekly vs monthly?\n- Interpret divergence between raw and rolling series.\n- Why pick `W` vs `MS`?\n\n### \ud83d\udd0e Quick checks\n- Report min/max dates in your index.\n- State the rolling window used and its effect.\n\n### \u2795 Extension (pick one)\n- Try a different window size and compare.\n- Plot both resampled and rolling series; note one change.\n\n**Rubric (10 pts):** Correctness 3 \u2022 Evidence 2 \u2022 Clarity 2 \u2022 Reproducibility 2 \u2022 Exploration 1"}, {"cell_type": "markdown", "metadata": {}, "source": "## 10) Rolling & Window Ops (10m)"}, {"cell_type": "code", "metadata": {}, "source": "daily = tips_ts.resample('D')[['total_bill']].sum()\ndaily['roll14_med'] = daily['total_bill'].rolling(14, min_periods=1).median()\ndaily[['total_bill','roll14_med']].head()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u270d\ufe0f Analysis (Rolling & Window Ops) \u2014 3\u20135 sentences\n- Why is median sometimes preferable to mean in rolling stats?\n- What happens at the edges for rolling windows?\n- When is `expanding` more suitable than `rolling`?\n\n### \ud83d\udd0e Quick checks\n- Show first 5 non-NaN rolling results.\n- Report `min_periods` and justify it.\n\n### \u2795 Extension (pick one)\n- Compute an additional rolling metric (std/min) and interpret.\n- Compare 7 vs 14-day windows with one sentence.\n\n**Rubric (10 pts):** Correctness 3 \u2022 Evidence 2 \u2022 Clarity 2 \u2022 Reproducibility 2 \u2022 Exploration 1"}, {"cell_type": "markdown", "metadata": {}, "source": "## 11) Text Data: vectorized & regex (10m)"}, {"cell_type": "code", "metadata": {}, "source": "notes = np.array(['VIP table','Late night','Allergic: nuts','Birthday','Family','vip guest'])\ntips_txt = tips.copy()\ntips_txt['note'] = np.resize(notes, len(tips_txt)).astype('string')\ntips_txt['is_vip'] = tips_txt['note'].str.contains('vip', case=False)\ntips_txt['allergy'] = tips_txt['note'].str.extract(r'Allergic:\\s*(\\w+)', expand=False)\ntips_txt[['note','is_vip','allergy']].head()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u270d\ufe0f Analysis (Text / Regex) \u2014 3\u20135 sentences\n- Which regex or string op gave most value here?\n- How sensitive are your results to case/spacing?\n- One potential false positive in your pattern.\n\n### \ud83d\udd0e Quick checks\n- Print counts of a detected flag (e.g., VIP).\n- Show unique extracted tokens (e.g., allergies).\n\n### \u2795 Extension (pick one)\n- Add a refined regex (word boundaries) and compare counts.\n- Normalize text further and re-check.\n\n**Rubric (10 pts):** Correctness 3 \u2022 Evidence 2 \u2022 Clarity 2 \u2022 Reproducibility 2 \u2022 Exploration 1"}, {"cell_type": "markdown", "metadata": {}, "source": "## 12) Nullable dtypes & Memory (5m)"}, {"cell_type": "code", "metadata": {}, "source": "tips_mem = tips.copy()\ntips_mem['size_N'] = tips_mem['size'].astype('Int64')\ntips_mem['sex_S']  = tips_mem['sex'].astype('string')\ntips_mem['day_C']  = tips_mem['day'].astype('category')\ntips_mem.memory_usage(deep=True)", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u270d\ufe0f Analysis (Dtypes & Memory) \u2014 3\u20135 sentences\n- What memory savings did `category` or `string` yield?\n- When would you avoid `category`?\n- Any effect on joins/groupbys?\n\n### \ud83d\udd0e Quick checks\n- Show `memory_usage(deep=True)` before/after one cast.\n- List `.cat.categories` for one column.\n\n### \u2795 Extension (pick one)\n- Downcast numerics where safe and report delta.\n- Switch one feature to `Int64` and explain why.\n\n**Rubric (10 pts):** Correctness 3 \u2022 Evidence 2 \u2022 Clarity 2 \u2022 Reproducibility 2 \u2022 Exploration 1"}, {"cell_type": "markdown", "metadata": {}, "source": "## 13) I/O: CSV, Parquet, JSON, SQL (10m)"}, {"cell_type": "code", "metadata": {}, "source": "subset = tips[['total_bill','tip','day','time','size']].head(20)\nsubset.to_csv('tips_sample.csv', index=False)\nsubset.to_parquet('tips_sample.parquet', index=False)\nsubset.to_json('tips_sample.json', orient='records', lines=True)\nimport sqlite3\ncon = sqlite3.connect(':memory:')\nsubset.to_sql('tips_tbl', con, index=False, if_exists='replace')\nsql_df = pd.read_sql('SELECT day, time, AVG(total_bill) AS avg_bill FROM tips_tbl GROUP BY day,time', con)\ncon.close(); sql_df.head()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u270d\ufe0f Analysis (I/O) \u2014 3\u20135 sentences\n- Which format is best for speed vs size for this table? Why?\n- Did any dtype change after round-trip?\n- When to use line-delimited JSON?\n\n### \ud83d\udd0e Quick checks\n- Compare shapes from CSV/Parquet/JSON loads.\n- Show one dtype discrepancy and fix it.\n\n### \u2795 Extension (pick one)\n- Compress CSV (gzip) and note file size.\n- Do a small SQL query and validate results match a groupby.\n\n**Rubric (10 pts):** Correctness 3 \u2022 Evidence 2 \u2022 Clarity 2 \u2022 Reproducibility 2 \u2022 Exploration 1"}, {"cell_type": "markdown", "metadata": {}, "source": "## 14) Join Patterns (10\u201315m)"}, {"cell_type": "code", "metadata": {}, "source": "left = tips[['day','time','size']].drop_duplicates().copy()\nright = tips[['day','time','tip']].groupby(['day','time']).mean().reset_index().rename(columns={'tip':'avg_tip'})\njoined = left.merge(right, on=['day','time'], how='outer', indicator=True)\njoined.head()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# Right-only and inner (semi-join-style)\nright_only = joined.loc[joined['_merge']=='right_only', right.columns]\ninner_rows = joined.loc[joined['_merge']=='both', left.columns].drop_duplicates()\nlen(inner_rows)", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "# merge_ordered and merge_asof demos\na = pd.DataFrame({'day':['Fri','Sat','Sun'], 'rank':[1,2,3]})\nb = pd.DataFrame({'day':['Thur','Sat','Sun'], 'score':[70,80,90]})\nordered = pd.merge_ordered(a, b, on='day', how='outer')\nevents = pd.DataFrame({'when': pd.to_datetime(['2024-01-01 10:00','2024-01-02 12:30','2024-01-04 09:00']),'event':['A','B','C']}).sort_values('when')\nmeasures = pd.DataFrame({'when': pd.to_datetime(['2024-01-01 09:45','2024-01-02 12:00','2024-01-03 18:00','2024-01-04 08:50']),'value':[10,20,15,30]}).sort_values('when')\nasof_join = pd.merge_asof(events, measures, on='when', direction='nearest', tolerance=pd.Timedelta('1H'))\nordered.head(), asof_join.head()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u270d\ufe0f Analysis (Joins) \u2014 3\u20135 sentences\n- Read `_indicator` results\u2014what mismatches did you find?\n- Where would `merge_asof` fit in a real pipeline?\n- Any ordering assumptions for `merge_ordered`?\n\n### \ud83d\udd0e Quick checks\n- Report counts for left/right/inner.\n- Show 2 sample rows from an anti-join.\n\n### \u2795 Extension (pick one)\n- Perform a semi-join and explain the use-case.\n- Add a composite key and re-merge.\n\n**Rubric (10 pts):** Correctness 3 \u2022 Evidence 2 \u2022 Clarity 2 \u2022 Reproducibility 2 \u2022 Exploration 1"}, {"cell_type": "markdown", "metadata": {}, "source": "## 15) Method Chaining & `.pipe`, `.query`, `.eval` (10m)"}, {"cell_type": "code", "metadata": {}, "source": "def add_bill_per_person(df): return df.assign(bill_per_person = df['total_bill']/df['size'])\npipe_demo = (tips.query(\"time=='Dinner'\").pipe(add_bill_per_person)\n             .groupby('day').agg(mean_bill_pp=('bill_per_person','mean'),\n                                 mean_tip_pct=('tip_pct','mean'))\n             .sort_values('mean_bill_pp', ascending=False))\neval_demo = tips.eval('bill_pp = total_bill / size')\npipe_demo.head(), eval_demo[['total_bill','size','bill_pp']].head()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u270d\ufe0f Analysis (Method Chaining) \u2014 3\u20135 sentences\n- What made the chained pipeline clearer or riskier?\n- Where would you break the chain for debugging?\n- When is `.eval` useful vs risky?\n\n### \ud83d\udd0e Quick checks\n- Show final columns of your pipeline result.\n- Confirm idempotency by re-running.\n\n### \u2795 Extension (pick one)\n- Refactor an earlier analysis into a chain; compare readability.\n- Encapsulate a step into `.pipe` and reuse it.\n\n**Rubric (10 pts):** Correctness 3 \u2022 Evidence 2 \u2022 Clarity 2 \u2022 Reproducibility 2 \u2022 Exploration 1"}, {"cell_type": "markdown", "metadata": {}, "source": "## 16) Crosstab, `cut/qcut`, `where/mask` (5\u201310m)"}, {"cell_type": "code", "metadata": {}, "source": "ct = pd.crosstab(tips['smoker'], tips['day'])\ntips_bins = tips.copy()\ntips_bins['bill_bucket'] = pd.cut(tips_bins['total_bill'], bins=[0,10,20,30,50])\nbucket_mean = tips_bins.groupby('bill_bucket')['tip'].mean()\ntips_q = tips.assign(q = pd.qcut(tips['tip_pct'], 4, duplicates='drop'))\nct, bucket_mean, tips_q.groupby('q')['total_bill'].mean()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u270d\ufe0f Analysis (Crosstab / Bucketing) \u2014 3\u20135 sentences\n- What story does your crosstab tell in one sentence?\n- How did `cut` vs `qcut` change bucket sizes?\n- When is `where` preferable to boolean indexing?\n\n### \ud83d\udd0e Quick checks\n- Show bucket edges and counts.\n- Verify monotonicity of bucket means if expected.\n\n### \u2795 Extension (pick one)\n- Swap `qcut`/`cut` and compare stats.\n- Mask outliers and re-summarize.\n\n**Rubric (10 pts):** Correctness 3 \u2022 Evidence 2 \u2022 Clarity 2 \u2022 Reproducibility 2 \u2022 Exploration 1"}, {"cell_type": "markdown", "metadata": {}, "source": "## 17) Styling & Export (5m)"}, {"cell_type": "code", "metadata": {}, "source": "sty = (tips.groupby('day')[['total_bill','tip','tip_pct']].mean().round(2)\n         .style.format({'tip_pct':'{:.2%}'}).background_gradient(axis=None))\nhtml = sty.to_html()\nopen('tips_report.html','w',encoding='utf-8').write(html)\n'Wrote tips_report.html'", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u270d\ufe0f Analysis (Styling & Export) \u2014 3\u20135 sentences\n- What formatting improved readability most?\n- How would a stakeholder use this HTML report?\n- One caution about styled HTML vs raw data files.\n\n### \ud83d\udd0e Quick checks\n- Open the HTML to spot issues (NA/odd values).\n- Confirm underlying numbers (pre-style) are correct.\n\n### \u2795 Extension (pick one)\n- Add one more style and explain choice.\n- Export both styled HTML and CSV for same table.\n\n**Rubric (10 pts):** Correctness 3 \u2022 Evidence 2 \u2022 Clarity 2 \u2022 Reproducibility 2 \u2022 Exploration 1"}, {"cell_type": "markdown", "metadata": {}, "source": "# Capstone Mini-Project (Free Dataset): **Titanic Survival Analysis** (30\u201345m)"}, {"cell_type": "markdown", "metadata": {}, "source": "**Source:** https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv"}, {"cell_type": "code", "metadata": {}, "source": "import pandas as pd, numpy as np, matplotlib.pyplot as plt", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "tit_url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\ntitanic = pd.read_csv(tit_url)\ntitanic.head()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "print(\"Shape:\", titanic.shape)\nprint(\"\\nInfo:\"); print(titanic.info())\nprint(\"\\nMissing values per column:\"); print(titanic.isna().sum().sort_values(ascending=False).head(12))", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "## A) Data Cleaning & Feature Engineering"}, {"cell_type": "code", "metadata": {}, "source": "df = titanic.copy()\nfor col in ['sex','class','embarked','embark_town','alive','who','deck','alone','adult_male']:\n    if col in df.columns: df[col] = df[col].astype('category')\nage_med = df.groupby(['sex','class'])['age'].transform('median')\ndf['age'] = df['age'].fillna(age_med)\nif df['embark_town'].isna().any():\n    mode_town = df['embark_town'].mode(dropna=True)\n    if not mode_town.empty: df['embark_town'] = df['embark_town'].fillna(mode_town.iloc[0])\ndf['family_size'] = df['sibsp'].fillna(0) + df['parch'].fillna(0) + 1\ndf['fare_pp'] = df['fare'] / df['family_size']\ndf['deck'] = df['deck'].cat.add_categories(['Unknown']).fillna('Unknown')\nbins = [0,12,18,35,50,80]; labels = ['Child','Teen','YoungAdult','MidAge','Senior']\ndf['age_group'] = pd.cut(df['age'], bins=bins, labels=labels, include_lowest=True)\ndf.head()", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u2705 Exercise A\nCheck NaNs in `age`/`embark_town`, top `family_size`, % with `fare_pp>20`."}, {"cell_type": "markdown", "metadata": {}, "source": "**Hints:**\n- Concept: impute & feature engineer.\n- API: `groupby().transform('median')`, `.mode()`, `.cut`.\n"}, {"cell_type": "code", "metadata": {}, "source": "# YOUR WORK: Exercise A", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "## B) Survival Patterns"}, {"cell_type": "code", "metadata": {}, "source": "overall_survival = df['survived'].mean(); print('Overall survival rate:', round(overall_survival,3))", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "surv_by_class = df.groupby('class')['survived'].mean().reindex(['First','Second','Third'])\nplt.figure(); plt.bar(surv_by_class.index.astype(str), surv_by_class.values)\nplt.title('Survival Rate by Class'); plt.xlabel('class'); plt.ylabel('survival rate'); plt.show()", "outputs": [], "execution_count": null}, {"cell_type": "code", "metadata": {}, "source": "piv = df.pivot_table(index='sex', columns='class', values='survived', aggfunc='mean')\nplt.figure(); plt.imshow(piv.values, aspect='auto')\nplt.title('Survival Rate by Sex \u00d7 Class'); plt.xlabel('class'); plt.ylabel('sex')\nplt.xticks(range(len(piv.columns)), piv.columns.astype(str))\nplt.yticks(range(len(piv.index)), piv.index.astype(str))\nplt.colorbar(); plt.show(); piv", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u2705 Exercise B\n1) Histogram of age. 2) Boxplot fare by class. 3) Bar of survival by age_group."}, {"cell_type": "markdown", "metadata": {}, "source": "**Hints:**\n- Concept: univariate + grouped visuals.\n- API: `plt.hist`, `plt.boxplot`, `groupby().mean` + `plt.bar`.\n"}, {"cell_type": "code", "metadata": {}, "source": "# YOUR WORK: Exercise B", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "## C) Subgroup Discovery"}, {"cell_type": "code", "metadata": {}, "source": "grp = (df.groupby(['sex','class','embark_town'])\n         .agg(n=('survived','size'), surv_rate=('survived','mean'))\n         .query('n >= 25')\n         .sort_values('surv_rate', ascending=False))\ngrp.head(10)", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u2705 Exercise C\nFamilies with `family_size\u22654`: survival by `sex` & `class` (n + rate). Bucket `fare_pp` and compute survival per bucket."}, {"cell_type": "markdown", "metadata": {}, "source": "**Hints:**\n- Concept: subgroup analysis with thresholds.\n- API: `groupby().agg`, `query`, `cut`.\n"}, {"cell_type": "code", "metadata": {}, "source": "# YOUR WORK: Exercise C", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "## D) Deliverables"}, {"cell_type": "code", "metadata": {}, "source": "top10 = grp.head(10).reset_index()\nsty = (top10.style.format({'surv_rate':'{:.2%}'}).hide(axis='index'))\nhtml = sty.to_html()\nopen('titanic_top10_survival.html','w',encoding='utf-8').write(html)\ntop10.to_csv('titanic_top10_survival.csv', index=False)\n\"Saved titanic_top10_survival.html and titanic_top10_survival.csv\"", "outputs": [], "execution_count": null}, {"cell_type": "markdown", "metadata": {}, "source": "### \u270d\ufe0f Analysis (Capstone \u2014 Titanic) \u2014 3\u20135 sentences\n- State your main finding (who/when/context) with one number and one plot reference.\n- Name one limitation in your approach (bias, leakage, imputation).\n- Suggest a next step or feature to add.\n\n### \ud83d\udd0e Quick checks\n- Link the exact cell/table backing your claim.\n- Confirm deliverables (HTML + CSV) were written.\n\n### \u2795 Extension (pick one)\n- Add an extra feature (e.g., `is_child`, z-scored fare) and see if subgroup ranking changes.\n- Try a different minimum group size and discuss stability.\n\n**Rubric (10 pts):** Correctness 3 \u2022 Evidence 2 \u2022 Clarity 2 \u2022 Reproducibility 2 \u2022 Exploration 1"}], "metadata": {"colab": {"name": "Pandas \u2014 Core + Advanced + Capstone (Base)"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}