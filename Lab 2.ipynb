{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üßë‚Äçüéì Student Version ‚Äî Solutions Removed\n",
    "- Use the reflection prompts and hints.\n",
    "- Your instructor will share solutions separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REVEAL_SOLUTIONS = False\n",
    "print('Solutions are hidden in the Student Version.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas in Google Colab ‚Äî 2-Hour Hands-On (+ Advanced & Capstone)\n",
    "**With Reflection Prompts After Each Section**\n",
    "**Last updated:** 2025-08-15\n",
    "\n",
    "Run top-to-bottom. Attempt **Exercises**, then write your **‚úçÔ∏è Analysis** under each section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Setup & Load the **tips** dataset (10m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_rows', 10); pd.set_option('display.precision', 3)\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv\"\n",
    "tips = pd.read_csv(url); tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape:\", tips.shape)\n",
    "print(\"\\nInfo:\"); print(tips.info())\n",
    "print(\"\\nDescribe:\"); display(tips.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Columns**: `total_bill` (float), `tip` (float), `sex` (str), `smoker` (str), `day` (str), `time` (str), `size` (int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Exercise 0\n",
    "1) Unique `day`, `time`. 2) Count duplicates. 3) Averages of `total_bill`, `tip`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hints:**\n",
    "- Concept: inspect levels and duplicates.\n",
    "- API: `unique`, `duplicated`, `mean`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR WORK: Exercise 0\n",
    "print(\"Unique Days:\", tips['day'].unique())\n",
    "print(\"Unique Times:\", tips['time'].unique())\n",
    "dc = tips.duplicated().sum()\n",
    "print(\"Number of duplicate rows:\", dc)\n",
    "avg = tips['total_bill'].mean()\n",
    "tip = tips['tip'].mean()\n",
    "print(\"Average Total Bill:\", round(avg, 2))\n",
    "print(\"Average Tip:\", round(tip, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Analysis (Setup & Load) ‚Äî 3‚Äì5 sentences\n",
    "- What columns and dtypes did you observe? Any surprises?\n",
    "- Is the dataset balanced across `day` and `time`? Cite one count.\n",
    "- One risk if you skip an initial audit here.\n",
    "\n",
    "### üîé Quick checks\n",
    "- Report the shape (rows, cols).\n",
    "- Name 1 non-numeric dtype and why it matters.\n",
    "\n",
    "### ‚ûï Extension (pick one)\n",
    "- Tweak display options and note the effect.\n",
    "- Compute `value_counts()` on `day` or `time`.\n",
    "\n",
    "**Rubric (10 pts):** Correctness 3 ‚Ä¢ Evidence 2 ‚Ä¢ Clarity 2 ‚Ä¢ Reproducibility 2 ‚Ä¢ Exploration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Import & Core Manipulation (20m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips[['total_bill','tip']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.loc[tips['day']=='Sun', ['total_bill','tip','size']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.query(\"time=='Lunch' and smoker=='Yes'\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.sort_values(['total_bill','tip'], ascending=[False, True]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = tips.assign(tip_pct = tips['tip']/tips['total_bill'],\n",
    "                         tip_per_person = tips['tip']/tips['size']); tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Exercise 1\n",
    "Filter `day='Sat' & size‚â•3`, add `bill_per_person`, sort desc, show top 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hints:**\n",
    "- Concept: filter ‚Üí compute ‚Üí sort.\n",
    "- API: boolean mask / `.query`, `.assign`, `.sort_values`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR WORK: Exercise 1\n",
    "tips.query(\"day == 'Sat' and size >= 3\").assign(bill_per_person = tips['total_bill'] / tips['size']).sort_values('bill_per_person', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Analysis (Import & Manipulation) ‚Äî 3‚Äì5 sentences\n",
    "- Which 2 columns seem most associated with `tip`? Support with a stat.\n",
    "- Explain one filter you wrote in plain English.\n",
    "- One thing you might compute next.\n",
    "\n",
    "### üîé Quick checks\n",
    "- Show first 3 rows of your filtered frame.\n",
    "- Name one new column and its formula.\n",
    "\n",
    "### ‚ûï Extension (pick one)\n",
    "- Rewrite a filter via `.query` vs mask; compare readability.\n",
    "- Change a sort order and predict effect.\n",
    "\n",
    "**Rubric (10 pts):** Correctness 3 ‚Ä¢ Evidence 2 ‚Ä¢ Clarity 2 ‚Ä¢ Reproducibility 2 ‚Ä¢ Exploration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Cleaning & Preprocessing (15m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips['sex']=tips['sex'].astype('category')\n",
    "tips['smoker']=tips['smoker'].astype('category')\n",
    "tips['day']=tips['day'].astype('category')\n",
    "tips['time']=tips['time'].astype('category'); tips.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips['server_name'] = [' Alice ', 'Bob', 'ALICE', 'bob', ' Alice ', 'Bob'] * (len(tips)//6) + ['Alice']*(len(tips)%6)\n",
    "tips['server_name'] = tips['server_name'].str.strip().str.title()\n",
    "tips['server_name'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = tips.copy()\n",
    "demo = pd.concat([demo, demo.iloc[0:2]], ignore_index=True)\n",
    "print(\"Before:\", demo.shape, \"After:\", demo.drop_duplicates().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Exercise 2\n",
    "1) Ensure `size` is int64. 2) Build `tips_clean` with selected cols. 3) Verify no duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hints:**\n",
    "- Concept: enforce types, subset columns, dedup.\n",
    "- API: `.astype`, column lists, `.drop_duplicates`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR WORK: Exercise 2\n",
    "# 1)\n",
    "tips['size'] = tips['size'].astype('int64')\n",
    "tips.head()\n",
    "# 2)\n",
    "clean = tips[[\"total_bill\", \"tip\", \"sex\", \"smoker\", \"day\", \"time\", \"size\", \"server_name\"]].copy()\n",
    "clean.head()\n",
    "print(\"Before:\",clean.shape, \"\\nAfter:\",clean.drop_duplicates().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Analysis (Cleaning & Preprocessing) ‚Äî 3‚Äì5 sentences\n",
    "- Which dtype changes did you apply and why?\n",
    "- Did you handle duplicates? How many?\n",
    "- One naming or string normalization you made.\n",
    "\n",
    "### üîé Quick checks\n",
    "- Print memory usage pre/post for 1 cast.\n",
    "- Confirm duplicates=0 in `tips_clean`.\n",
    "\n",
    "### ‚ûï Extension (pick one)\n",
    "- Cast another column and report memory delta.\n",
    "- Show `.value_counts()` pre/post string cleanup.\n",
    "\n",
    "**Rubric (10 pts):** Correctness 3 ‚Ä¢ Evidence 2 ‚Ä¢ Clarity 2 ‚Ä¢ Reproducibility 2 ‚Ä¢ Exploration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Handling Missing Data (15m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "tips_na = tips_clean.copy()\n",
    "mask = rng.choice([True, False], size=len(tips_na), p=[0.1, 0.9])\n",
    "tips_na.loc[mask, 'tip'] = np.nan; tips_na.loc[mask, 'size'] = np.nan\n",
    "tips_na.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped = tips_na.dropna(); dropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled = tips_na.fillna({'tip': tips_na['tip'].median(), 'size': tips_na['size'].median()}); filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_group_fill = tips_na.copy()\n",
    "tips_group_fill['tip'] = tips_group_fill.groupby(['day','time'])['tip'].transform(lambda s: s.fillna(s.median()))\n",
    "tips_group_fill.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_interp = tips_na.sort_values('total_bill').interpolate(numeric_only=True); tips_interp.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Exercise 3\n",
    "Drop rows where both `tip` & `size` are NaN; fill `size` by rounded mean per `day`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hints:**\n",
    "- Concept: selective drop, grouped fill.\n",
    "- API: boolean masks, `groupby().transform`, `.fillna`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR WORK: Exercise 3\n",
    "t = tips_na.copy()\n",
    "mask = t['tip'].isna() & t['size'].isna()\n",
    "t = t[~mask]\n",
    "t['size'] = t.groupby('day')['size'].transform(lambda s: s.fillna(round(s.mean())))\n",
    "print(t.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Analysis (Missing Data) ‚Äî 3‚Äì5 sentences\n",
    "- Compare `dropna` vs groupwise fill‚Äîwho shifts distribution more?\n",
    "- What assumption does your fill strategy make?\n",
    "- When would interpolation be inappropriate here?\n",
    "\n",
    "### üîé Quick checks\n",
    "- Report NaN counts before vs after.\n",
    "- Cite one numeric change for `tip`.\n",
    "\n",
    "### ‚ûï Extension (pick one)\n",
    "- Try a different group key for fill and compare MAE.\n",
    "- Plot hist pre/post fill for `tip`.\n",
    "\n",
    "**Rubric (10 pts):** Correctness 3 ‚Ä¢ Evidence 2 ‚Ä¢ Clarity 2 ‚Ä¢ Reproducibility 2 ‚Ä¢ Exploration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Analysis & Visualization (20m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Overall tip %:\", (tips['tip'].sum()/tips['total_bill'].sum()).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(); plt.hist(tips['total_bill'].dropna(), bins=20)\n",
    "plt.title('Histogram: total_bill'); plt.xlabel('total_bill'); plt.ylabel('Frequency'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "data = [tips.loc[tips['day']==d, 'tip'].dropna().values for d in tips['day'].cat.categories]\n",
    "plt.boxplot(data, labels=list(tips['day'].cat.categories))\n",
    "plt.title('Boxplot: tip by day'); plt.xlabel('day'); plt.ylabel('tip'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(); plt.scatter(tips['total_bill'], tips['tip'], s=tips['size']*10, alpha=0.6)\n",
    "plt.title('Scatter: total_bill vs tip'); plt.xlabel('total_bill'); plt.ylabel('tip'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tip_pct = tips.groupby('day')['tip_pct'].mean()\n",
    "plt.figure(); plt.bar(avg_tip_pct.index.astype(str), avg_tip_pct.values)\n",
    "plt.title('Average tip_pct by day'); plt.xlabel('day'); plt.ylabel('mean tip_pct'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Exercise 4\n",
    "1) Scatter: `total_bill` vs `tip_pct`. 2) Bar: median `total_bill` by `time`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hints:**\n",
    "- Concept: relate vars via scatter; summarize via bar.\n",
    "- API: `plt.scatter`, `groupby().median` + `plt.bar`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR WORK: Exercise 4\n",
    "plt.figure()\n",
    "plt.scatter(tips['total_bill'], tips['tip_pct'], alpha=0.6)\n",
    "plt.title('Scatter: total_bill vs tip_pct')\n",
    "plt.xlabel('total_bill')\n",
    "plt.ylabel('tip_pct')\n",
    "plt.show()\n",
    "median_bill = tips.groupby('time')['total_bill'].median()\n",
    "plt.figure()\n",
    "plt.bar(median_bill.index.astype(str), median_bill.values)\n",
    "plt.title('Median total_bill by time')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('median total_bill')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Analysis (Analysis & Visualization) ‚Äî 3‚Äì5 sentences\n",
    "- State one pattern that holds across days and one that differs Lunch vs Dinner.\n",
    "- Interpret scatter: linear? heteroscedastic?\n",
    "- What would you plot next?\n",
    "\n",
    "### üîé Quick checks\n",
    "- Quote one `.describe()` stat that supports your claim.\n",
    "- Ensure axes labels/titles are informative.\n",
    "\n",
    "### ‚ûï Extension (pick one)\n",
    "- Add a follow-up chart (e.g., tip% by party size) and describe it.\n",
    "- Bucket `total_bill` and compare medians.\n",
    "\n",
    "**Rubric (10 pts):** Correctness 3 ‚Ä¢ Evidence 2 ‚Ä¢ Clarity 2 ‚Ä¢ Reproducibility 2 ‚Ä¢ Exploration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Grouping & Merging (20m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = (tips.groupby(['day','time'])\n",
    "       .agg(count=('total_bill','size'), avg_bill=('total_bill','mean'),\n",
    "            avg_tip=('tip','mean'), avg_tip_pct=('tip_pct','mean'))); g.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_above_20(s): return (s>0.20).mean()\n",
    "\n",
    "tips.groupby('day')['tip_pct'].apply(pct_above_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_lookup = pd.DataFrame({'day':['Thur','Fri','Sat','Sun'],'is_weekend':[False,False,True,True]})\n",
    "tips_merge = tips.merge(day_lookup, on='day', how='left')\n",
    "tips_merge[['day','is_weekend']].drop_duplicates().sort_values('day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Exercise 5\n",
    "1) Sum `total_bill` & `tip` by `smoker,sex`. 2) Map `time`‚ÜíL/D and show pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hints:**\n",
    "- Concept: summarize by groups; enrich via merge.\n",
    "- API: `groupby().agg`, `.merge`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR WORK: Exercise 5\n",
    "t = tips.groupby([\"smoker\", \"sex\"]).agg(\n",
    "    sum=(\"total_bill\", \"sum\"),\n",
    "    tsum=(\"tip\", \"sum\")\n",
    ").reset_index()\n",
    "\n",
    "print(t)\n",
    "\n",
    "\n",
    "t = pd.DataFrame({\n",
    "    \"time\": [\"Lunch\", \"Dinner\"],\n",
    "    \"meal\": [\"L\", \"D\"]\n",
    "})\n",
    "t1 = tips.merge(t, on=\"time\", how=\"left\")\n",
    "print(t1[[\"time\", \"meal\"]].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Analysis (Grouping & Merging) ‚Äî 3‚Äì5 sentences\n",
    "- Translate one grouped table into a business insight.\n",
    "- How does `tip_pct` vs `tip` change ranking?\n",
    "- What join-key assumptions are you making?\n",
    "\n",
    "### üîé Quick checks\n",
    "- Show index/columns of grouped result.\n",
    "- Check row counts before/after a merge.\n",
    "\n",
    "### ‚ûï Extension (pick one)\n",
    "- Add `avg_tip_pp` and re-rank groups.\n",
    "- Outer join with `_indicator` and explain one mismatch.\n",
    "\n",
    "**Rubric (10 pts):** Correctness 3 ‚Ä¢ Evidence 2 ‚Ä¢ Clarity 2 ‚Ä¢ Reproducibility 2 ‚Ä¢ Exploration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Reshaping & Pivoting (15m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piv = tips.pivot_table(index='day', columns='time', values='tip_pct', aggfunc='mean'); piv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long = tips[['day','time','total_bill','tip']].melt(id_vars=['day','time'], var_name='metric', value_name='value'); long.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Exercise 6\n",
    "1) Pivot mean `total_bill` by `size`√ó`day`. 2) Melt back to long with `size` as id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hints:**\n",
    "- Concept: reshape wide‚Üîlong.\n",
    "- API: `pivot_table`, `melt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR WORK: Exercise 6\n",
    "t = tips.pivot_table(\n",
    "    index=\"day\",\n",
    "    columns=\"size\",\n",
    "    values=\"total_bill\",\n",
    "    aggfunc=\"mean\"\n",
    ")\n",
    "\n",
    "print(t)\n",
    "l = t.reset_index().melt(\n",
    "    id_vars=\"day\",\n",
    "    var_name=\"size\",\n",
    "    value_name=\"mean_total_bill\"\n",
    ")\n",
    "\n",
    "print(l.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Analysis (Reshaping & Pivoting) ‚Äî 3‚Äì5 sentences\n",
    "- When did `pivot_table` drop rows/cols vs `melt`?\n",
    "- Explain wide‚Üîlong trade-offs here.\n",
    "- Which format suits your chosen chart and why?\n",
    "\n",
    "### üîé Quick checks\n",
    "- Confirm shapes of pivot vs long tables.\n",
    "- List index/columns used in your pivot.\n",
    "\n",
    "### ‚ûï Extension (pick one)\n",
    "- Change `aggfunc` and compare results.\n",
    "- Add a second dimension in pivot.\n",
    "\n",
    "**Rubric (10 pts):** Correctness 3 ‚Ä¢ Evidence 2 ‚Ä¢ Clarity 2 ‚Ä¢ Reproducibility 2 ‚Ä¢ Exploration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Mini-Project: When are tips the most generous? (5‚Äì10m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piv = tips.pivot_table(index='day', columns='time', values='tip_pct', aggfunc='mean')\n",
    "print(piv.stack().sort_values(ascending=False).head(5))\n",
    "plt.figure(); plt.imshow(piv.values, aspect='auto')\n",
    "plt.title('Mean tip_pct by day & time'); plt.xlabel('time'); plt.ylabel('day')\n",
    "plt.xticks(range(len(piv.columns)), piv.columns.astype(str))\n",
    "plt.yticks(range(len(piv.index)), piv.index.astype(str))\n",
    "plt.colorbar(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Analysis (Mini-Project (Tips Generosity)) ‚Äî 3‚Äì5 sentences\n",
    "- State your top day√ótime combo with mean `tip_pct`.\n",
    "- Is it robust to outliers? How to check?\n",
    "- One follow-up action for a restaurant.\n",
    "\n",
    "### üîé Quick checks\n",
    "- Show top 3 combos and their counts.\n",
    "- Confirm sample size for top combo.\n",
    "\n",
    "### ‚ûï Extension (pick one)\n",
    "- Recompute using median `tip_pct`.\n",
    "- Exclude size<2 and compare ranking.\n",
    "\n",
    "**Rubric (10 pts):** Correctness 3 ‚Ä¢ Evidence 2 ‚Ä¢ Clarity 2 ‚Ä¢ Reproducibility 2 ‚Ä¢ Exploration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Module ‚Äî Daily Operations Coverage (~60‚Äì75m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Indexes & MultiIndex (10m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti = tips.set_index(['day','time']).sort_index()\n",
    "ti.loc[('Sat','Dinner')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti.groupby(level=['day','time'])['tip_pct'].mean().reset_index(name='mean_tip_pct').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Analysis (Indexes & MultiIndex) ‚Äî 3‚Äì5 sentences\n",
    "- What did a MultiIndex buy you over flat columns?\n",
    "- Give one easier slice enabled by the index.\n",
    "- Any pitfalls when saving/loading with MultiIndex?\n",
    "\n",
    "### üîé Quick checks\n",
    "- Print `.index.names` and level dtypes.\n",
    "- Show one `.loc` label slice on multi-level.\n",
    "\n",
    "### ‚ûï Extension (pick one)\n",
    "- Swap levels and explain slicing change.\n",
    "- Reset index and compare to original columns.\n",
    "\n",
    "**Rubric (10 pts):** Correctness 3 ‚Ä¢ Evidence 2 ‚Ä¢ Clarity 2 ‚Ä¢ Reproducibility 2 ‚Ä¢ Exploration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Time Series & Resampling (15m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_ts = tips.copy()\n",
    "tips_ts['date'] = pd.to_datetime('2024-01-01') + pd.to_timedelta(np.arange(len(tips_ts)), unit='D')\n",
    "tips_ts = tips_ts.set_index('date').sort_index()\n",
    "weekly = tips_ts.resample('W')[['total_bill','tip']].sum()\n",
    "weekly['tip_pct'] = weekly['tip']/weekly['total_bill']\n",
    "weekly['tip_pct_roll4'] = weekly['tip_pct'].rolling(4, min_periods=1).mean()\n",
    "weekly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Analysis (Time Series & Resampling) ‚Äî 3‚Äì5 sentences\n",
    "- What trend do you see weekly vs monthly?\n",
    "- Interpret divergence between raw and rolling series.\n",
    "- Why pick `W` vs `MS`?\n",
    "\n",
    "### üîé Quick checks\n",
    "- Report min/max dates in your index.\n",
    "- State the rolling window used and its effect.\n",
    "\n",
    "### ‚ûï Extension (pick one)\n",
    "- Try a different window size and compare.\n",
    "- Plot both resampled and rolling series; note one change.\n",
    "\n",
    "**Rubric (10 pts):** Correctness 3 ‚Ä¢ Evidence 2 ‚Ä¢ Clarity 2 ‚Ä¢ Reproducibility 2 ‚Ä¢ Exploration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Rolling & Window Ops (10m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily = tips_ts.resample('D')[['total_bill']].sum()\n",
    "daily['roll14_med'] = daily['total_bill'].rolling(14, min_periods=1).median()\n",
    "daily[['total_bill','roll14_med']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Analysis (Rolling & Window Ops) ‚Äî 3‚Äì5 sentences\n",
    "- Why is median sometimes preferable to mean in rolling stats?\n",
    "- What happens at the edges for rolling windows?\n",
    "- When is `expanding` more suitable than `rolling`?\n",
    "\n",
    "### üîé Quick checks\n",
    "- Show first 5 non-NaN rolling results.\n",
    "- Report `min_periods` and justify it.\n",
    "\n",
    "### ‚ûï Extension (pick one)\n",
    "- Compute an additional rolling metric (std/min) and interpret.\n",
    "- Compare 7 vs 14-day windows with one sentence.\n",
    "\n",
    "**Rubric (10 pts):** Correctness 3 ‚Ä¢ Evidence 2 ‚Ä¢ Clarity 2 ‚Ä¢ Reproducibility 2 ‚Ä¢ Exploration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Text Data: vectorized & regex (10m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = np.array(['VIP table','Late night','Allergic: nuts','Birthday','Family','vip guest'])\n",
    "tips_txt = tips.copy()\n",
    "tips_txt['note'] = np.resize(notes, len(tips_txt)).astype('string')\n",
    "tips_txt['is_vip'] = tips_txt['note'].str.contains('vip', case=False)\n",
    "tips_txt['allergy'] = tips_txt['note'].str.extract(r'Allergic:\\s*(\\w+)', expand=False)\n",
    "tips_txt[['note','is_vip','allergy']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Analysis (Text / Regex) ‚Äî 3‚Äì5 sentences\n",
    "- Which regex or string op gave most value here?\n",
    "- How sensitive are your results to case/spacing?\n",
    "- One potential false positive in your pattern.\n",
    "\n",
    "### üîé Quick checks\n",
    "- Print counts of a detected flag (e.g., VIP).\n",
    "- Show unique extracted tokens (e.g., allergies).\n",
    "\n",
    "### ‚ûï Extension (pick one)\n",
    "- Add a refined regex (word boundaries) and compare counts.\n",
    "- Normalize text further and re-check.\n",
    "\n",
    "**Rubric (10 pts):** Correctness 3 ‚Ä¢ Evidence 2 ‚Ä¢ Clarity 2 ‚Ä¢ Reproducibility 2 ‚Ä¢ Exploration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12) Nullable dtypes & Memory (5m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_mem = tips.copy()\n",
    "tips_mem['size_N'] = tips_mem['size'].astype('Int64')\n",
    "tips_mem['sex_S']  = tips_mem['sex'].astype('string')\n",
    "tips_mem['day_C']  = tips_mem['day'].astype('category')\n",
    "tips_mem.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Analysis (Dtypes & Memory) ‚Äî 3‚Äì5 sentences\n",
    "- What memory savings did `category` or `string` yield?\n",
    "- When would you avoid `category`?\n",
    "- Any effect on joins/groupbys?\n",
    "\n",
    "### üîé Quick checks\n",
    "- Show `memory_usage(deep=True)` before/after one cast.\n",
    "- List `.cat.categories` for one column.\n",
    "\n",
    "### ‚ûï Extension (pick one)\n",
    "- Downcast numerics where safe and report delta.\n",
    "- Switch one feature to `Int64` and explain why.\n",
    "\n",
    "**Rubric (10 pts):** Correctness 3 ‚Ä¢ Evidence 2 ‚Ä¢ Clarity 2 ‚Ä¢ Reproducibility 2 ‚Ä¢ Exploration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13) I/O: CSV, Parquet, JSON, SQL (10m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = tips[['total_bill','tip','day','time','size']].head(20)\n",
    "subset.to_csv('tips_sample.csv', index=False)\n",
    "subset.to_parquet('tips_sample.parquet', index=False)\n",
    "subset.to_json('tips_sample.json', orient='records', lines=True)\n",
    "import sqlite3\n",
    "con = sqlite3.connect(':memory:')\n",
    "subset.to_sql('tips_tbl', con, index=False, if_exists='replace')\n",
    "sql_df = pd.read_sql('SELECT day, time, AVG(total_bill) AS avg_bill FROM tips_tbl GROUP BY day,time', con)\n",
    "con.close(); sql_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Analysis (I/O) ‚Äî 3‚Äì5 sentences\n",
    "- Which format is best for speed vs size for this table? Why?\n",
    "- Did any dtype change after round-trip?\n",
    "- When to use line-delimited JSON?\n",
    "\n",
    "### üîé Quick checks\n",
    "- Compare shapes from CSV/Parquet/JSON loads.\n",
    "- Show one dtype discrepancy and fix it.\n",
    "\n",
    "### ‚ûï Extension (pick one)\n",
    "- Compress CSV (gzip) and note file size.\n",
    "- Do a small SQL query and validate results match a groupby.\n",
    "\n",
    "**Rubric (10 pts):** Correctness 3 ‚Ä¢ Evidence 2 ‚Ä¢ Clarity 2 ‚Ä¢ Reproducibility 2 ‚Ä¢ Exploration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14) Join Patterns (10‚Äì15m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = tips[['day','time','size']].drop_duplicates().copy()\n",
    "right = tips[['day','time','tip']].groupby(['day','time']).mean().reset_index().rename(columns={'tip':'avg_tip'})\n",
    "joined = left.merge(right, on=['day','time'], how='outer', indicator=True)\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right-only and inner (semi-join-style)\n",
    "right_only = joined.loc[joined['_merge']=='right_only', right.columns]\n",
    "inner_rows = joined.loc[joined['_merge']=='both', left.columns].drop_duplicates()\n",
    "len(inner_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_ordered and merge_asof demos\n",
    "a = pd.DataFrame({'day':['Fri','Sat','Sun'], 'rank':[1,2,3]})\n",
    "b = pd.DataFrame({'day':['Thur','Sat','Sun'], 'score':[70,80,90]})\n",
    "ordered = pd.merge_ordered(a, b, on='day', how='outer')\n",
    "events = pd.DataFrame({'when': pd.to_datetime(['2024-01-01 10:00','2024-01-02 12:30','2024-01-04 09:00']),'event':['A','B','C']}).sort_values('when')\n",
    "measures = pd.DataFrame({'when': pd.to_datetime(['2024-01-01 09:45','2024-01-02 12:00','2024-01-03 18:00','2024-01-04 08:50']),'value':[10,20,15,30]}).sort_values('when')\n",
    "asof_join = pd.merge_asof(events, measures, on='when', direction='nearest', tolerance=pd.Timedelta('1H'))\n",
    "ordered.head(), asof_join.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Analysis (Joins) ‚Äî 3‚Äì5 sentences\n",
    "- Read `_indicator` results‚Äîwhat mismatches did you find?\n",
    "- Where would `merge_asof` fit in a real pipeline?\n",
    "- Any ordering assumptions for `merge_ordered`?\n",
    "\n",
    "### üîé Quick checks\n",
    "- Report counts for left/right/inner.\n",
    "- Show 2 sample rows from an anti-join.\n",
    "\n",
    "### ‚ûï Extension (pick one)\n",
    "- Perform a semi-join and explain the use-case.\n",
    "- Add a composite key and re-merge.\n",
    "\n",
    "**Rubric (10 pts):** Correctness 3 ‚Ä¢ Evidence 2 ‚Ä¢ Clarity 2 ‚Ä¢ Reproducibility 2 ‚Ä¢ Exploration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15) Method Chaining & `.pipe`, `.query`, `.eval` (10m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bill_per_person(df): return df.assign(bill_per_person = df['total_bill']/df['size'])\n",
    "pipe_demo = (tips.query(\"time=='Dinner'\").pipe(add_bill_per_person)\n",
    "             .groupby('day').agg(mean_bill_pp=('bill_per_person','mean'),\n",
    "                                 mean_tip_pct=('tip_pct','mean'))\n",
    "             .sort_values('mean_bill_pp', ascending=False))\n",
    "eval_demo = tips.eval('bill_pp = total_bill / size')\n",
    "pipe_demo.head(), eval_demo[['total_bill','size','bill_pp']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Analysis (Method Chaining) ‚Äî 3‚Äì5 sentences\n",
    "- What made the chained pipeline clearer or riskier?\n",
    "- Where would you break the chain for debugging?\n",
    "- When is `.eval` useful vs risky?\n",
    "\n",
    "### üîé Quick checks\n",
    "- Show final columns of your pipeline result.\n",
    "- Confirm idempotency by re-running.\n",
    "\n",
    "### ‚ûï Extension (pick one)\n",
    "- Refactor an earlier analysis into a chain; compare readability.\n",
    "- Encapsulate a step into `.pipe` and reuse it.\n",
    "\n",
    "**Rubric (10 pts):** Correctness 3 ‚Ä¢ Evidence 2 ‚Ä¢ Clarity 2 ‚Ä¢ Reproducibility 2 ‚Ä¢ Exploration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16) Crosstab, `cut/qcut`, `where/mask` (5‚Äì10m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = pd.crosstab(tips['smoker'], tips['day'])\n",
    "tips_bins = tips.copy()\n",
    "tips_bins['bill_bucket'] = pd.cut(tips_bins['total_bill'], bins=[0,10,20,30,50])\n",
    "bucket_mean = tips_bins.groupby('bill_bucket')['tip'].mean()\n",
    "tips_q = tips.assign(q = pd.qcut(tips['tip_pct'], 4, duplicates='drop'))\n",
    "ct, bucket_mean, tips_q.groupby('q')['total_bill'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Analysis (Crosstab / Bucketing) ‚Äî 3‚Äì5 sentences\n",
    "- What story does your crosstab tell in one sentence?\n",
    "- How did `cut` vs `qcut` change bucket sizes?\n",
    "- When is `where` preferable to boolean indexing?\n",
    "\n",
    "### üîé Quick checks\n",
    "- Show bucket edges and counts.\n",
    "- Verify monotonicity of bucket means if expected.\n",
    "\n",
    "### ‚ûï Extension (pick one)\n",
    "- Swap `qcut`/`cut` and compare stats.\n",
    "- Mask outliers and re-summarize.\n",
    "\n",
    "**Rubric (10 pts):** Correctness 3 ‚Ä¢ Evidence 2 ‚Ä¢ Clarity 2 ‚Ä¢ Reproducibility 2 ‚Ä¢ Exploration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17) Styling & Export (5m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sty = (tips.groupby('day')[['total_bill','tip','tip_pct']].mean().round(2)\n",
    "         .style.format({'tip_pct':'{:.2%}'}).background_gradient(axis=None))\n",
    "html = sty.to_html()\n",
    "open('tips_report.html','w',encoding='utf-8').write(html)\n",
    "'Wrote tips_report.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Analysis (Styling & Export) ‚Äî 3‚Äì5 sentences\n",
    "- What formatting improved readability most?\n",
    "- How would a stakeholder use this HTML report?\n",
    "- One caution about styled HTML vs raw data files.\n",
    "\n",
    "### üîé Quick checks\n",
    "- Open the HTML to spot issues (NA/odd values).\n",
    "- Confirm underlying numbers (pre-style) are correct.\n",
    "\n",
    "### ‚ûï Extension (pick one)\n",
    "- Add one more style and explain choice.\n",
    "- Export both styled HTML and CSV for same table.\n",
    "\n",
    "**Rubric (10 pts):** Correctness 3 ‚Ä¢ Evidence 2 ‚Ä¢ Clarity 2 ‚Ä¢ Reproducibility 2 ‚Ä¢ Exploration 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Mini-Project (Free Dataset): **Titanic Survival Analysis** (30‚Äì45m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Source:** https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tit_url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "titanic = pd.read_csv(tit_url)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape:\", titanic.shape)\n",
    "print(\"\\nInfo:\"); print(titanic.info())\n",
    "print(\"\\nMissing values per column:\"); print(titanic.isna().sum().sort_values(ascending=False).head(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Data Cleaning & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = titanic.copy()\n",
    "for col in ['sex','class','embarked','embark_town','alive','who','deck','alone','adult_male']:\n",
    "    if col in df.columns: df[col] = df[col].astype('category')\n",
    "age_med = df.groupby(['sex','class'])['age'].transform('median')\n",
    "df['age'] = df['age'].fillna(age_med)\n",
    "if df['embark_town'].isna().any():\n",
    "    mode_town = df['embark_town'].mode(dropna=True)\n",
    "    if not mode_town.empty: df['embark_town'] = df['embark_town'].fillna(mode_town.iloc[0])\n",
    "df['family_size'] = df['sibsp'].fillna(0) + df['parch'].fillna(0) + 1\n",
    "df['fare_pp'] = df['fare'] / df['family_size']\n",
    "df['deck'] = df['deck'].cat.add_categories(['Unknown']).fillna('Unknown')\n",
    "bins = [0,12,18,35,50,80]; labels = ['Child','Teen','YoungAdult','MidAge','Senior']\n",
    "df['age_group'] = pd.cut(df['age'], bins=bins, labels=labels, include_lowest=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Exercise A\n",
    "Check NaNs in `age`/`embark_town`, top `family_size`, % with `fare_pp>20`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hints:**\n",
    "- Concept: impute & feature engineer.\n",
    "- API: `groupby().transform('median')`, `.mode()`, `.cut`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR WORK: Exercise A\n",
    "nan_age = df['age'].isna().sum()\n",
    "nan_embark_town = df['embark_town'].isna().sum()\n",
    "print(f\"Missing values - Age: {nan_age}, Embark Town: {nan_embark_town}\")\n",
    "top_families = df['family_size'].value_counts().head(10)\n",
    "print(\"\\nTop 10 family sizes:\\n\", top_families)\n",
    "fare_pp_over_20 = (df['fare_pp'] > 20).sum()\n",
    "total_passengers = df.shape[0]\n",
    "percentage_high_fare = (fare_pp_over_20 / total_passengers) * 100\n",
    "print(f\"\\nPercentage of passengers with fare_pp > 20: {percentage_high_fare:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Survival Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_survival = df['survived'].mean(); print('Overall survival rate:', round(overall_survival,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv_by_class = df.groupby('class')['survived'].mean().reindex(['First','Second','Third'])\n",
    "plt.figure(); plt.bar(surv_by_class.index.astype(str), surv_by_class.values)\n",
    "plt.title('Survival Rate by Class'); plt.xlabel('class'); plt.ylabel('survival rate'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "piv = df.pivot_table(index='sex', columns='class', values='survived', aggfunc='mean')\n",
    "plt.figure(); plt.imshow(piv.values, aspect='auto')\n",
    "plt.title('Survival Rate by Sex √ó Class'); plt.xlabel('class'); plt.ylabel('sex')\n",
    "plt.xticks(range(len(piv.columns)), piv.columns.astype(str))\n",
    "plt.yticks(range(len(piv.index)), piv.index.astype(str))\n",
    "plt.colorbar(); plt.show(); piv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Exercise B\n",
    "1) Histogram of age. 2) Boxplot fare by class. 3) Bar of survival by age_group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hints:**\n",
    "- Concept: univariate + grouped visuals.\n",
    "- API: `plt.hist`, `plt.boxplot`, `groupby().mean` + `plt.bar`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR WORK: Exercise B\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(df['age'], bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Age Distribution of Passengers')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "plt.figure(figsize=(8,5))\n",
    "classes = ['First', 'Second', 'Third']\n",
    "fare_by_class = [df[df['class'] == c]['fare'] for c in classes]\n",
    "plt.boxplot(fare_by_class, labels=classes)\n",
    "plt.title('Fare Distribution by Class')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Fare')\n",
    "plt.show()\n",
    "surv_by_agegroup = df.groupby('age_group')['survived'].mean()\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(surv_by_agegroup.index.astype(str), surv_by_agegroup.values, color='lightgreen', edgecolor='black')\n",
    "plt.title('Survival Rate by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Survival Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Subgroup Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = (df.groupby(['sex','class','embark_town'])\n",
    "         .agg(n=('survived','size'), surv_rate=('survived','mean'))\n",
    "         .query('n >= 25')\n",
    "         .sort_values('surv_rate', ascending=False))\n",
    "grp.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Exercise C\n",
    "Families with `family_size‚â•4`: survival by `sex` & `class` (n + rate). Bucket `fare_pp` and compute survival per bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hints:**\n",
    "- Concept: subgroup analysis with thresholds.\n",
    "- API: `groupby().agg`, `query`, `cut`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR WORK: Exercise C\n",
    "large_families = (df[df['family_size'] >= 4]\n",
    "                  .groupby(['sex', 'class'])\n",
    "                  .agg(n=('survived', 'size'),\n",
    "                       surv_rate=('survived', 'mean'))\n",
    "                  .sort_values('surv_rate', ascending=False))\n",
    "print(\"Survival for large families (family_size >=4):\\n\", large_families)\n",
    "fare_bins = [0, 10, 20, 30, 50, 100, 600]\n",
    "fare_labels = ['0-10', '10-20', '20-30', '30-50', '50-100', '100+']\n",
    "df['fare_pp_bucket'] = pd.cut(df['fare_pp'], bins=fare_bins, labels=fare_labels, include_lowest=True)\n",
    "surv_by_fare_bucket = df.groupby('fare_pp_bucket')['survived'].agg(['size','mean']).rename(columns={'size':'n','mean':'surv_rate'})\n",
    "print(\"\\nSurvival by fare_pp bucket:\\n\", surv_by_fare_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D) Deliverables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10 = grp.head(10).reset_index()\n",
    "sty = (top10.style.format({'surv_rate':'{:.2%}'}).hide(axis='index'))\n",
    "html = sty.to_html()\n",
    "open('titanic_top10_survival.html','w',encoding='utf-8').write(html)\n",
    "top10.to_csv('titanic_top10_survival.csv', index=False)\n",
    "\"Saved titanic_top10_survival.html and titanic_top10_survival.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Analysis (Capstone ‚Äî Titanic) ‚Äî 3‚Äì5 sentences\n",
    "- State your main finding (who/when/context) with one number and one plot reference.\n",
    "- Name one limitation in your approach (bias, leakage, imputation).\n",
    "- Suggest a next step or feature to add.\n",
    "\n",
    "### üîé Quick checks\n",
    "- Link the exact cell/table backing your claim.\n",
    "- Confirm deliverables (HTML + CSV) were written.\n",
    "\n",
    "### ‚ûï Extension (pick one)\n",
    "- Add an extra feature (e.g., `is_child`, z-scored fare) and see if subgroup ranking changes.\n",
    "- Try a different minimum group size and discuss stability.\n",
    "\n",
    "**Rubric (10 pts):** Correctness 3 ‚Ä¢ Evidence 2 ‚Ä¢ Clarity 2 ‚Ä¢ Reproducibility 2 ‚Ä¢ Exploration 1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Pandas ‚Äî Core + Advanced + Capstone (Base)"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
